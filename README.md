# ğŸŒ€ Pipeline Kafka Connect: PostgreSQL (Gold) â†’ Kafka â†’ AWS S3

## ğŸ“˜ DescriÃ§Ã£o

Este projeto implementa um pipeline de streaming e persistÃªncia de dados que conecta as **tabelas Gold** do PostgreSQL (`dadostesouroipca_gold` e `dadostesouropre_gold`) a **tÃ³picos Kafka**, e posteriormente envia esses dados para a **AWS S3** em formato JSON.  

O objetivo Ã© garantir a **sincronizaÃ§Ã£o contÃ­nua** dos dados processados (camada Gold) com sistemas downstream, como data lakes ou ferramentas de anÃ¡lise.

---

## ğŸ§± Arquitetura do Pipeline

1. **ğŸ“¡ Fonte de Dados:** PostgreSQL (camada Gold: IPCA e Prefixado)
2. **ğŸ”„ Kafka Connect - JDBC Source:** extrai dados do PostgreSQL e publica nos tÃ³picos Kafka
3. **ğŸ§© Kafka Broker:** armazena os tÃ³picos atualizados
4. **ğŸŒ© Kafka Connect - S3 Sink:** consome os tÃ³picos e escreve arquivos `.json` em um bucket AWS S3

---

## âš™ï¸ ConfiguraÃ§Ã£o dos Conectores

### ğŸ”Œ JDBC Source Connector

- Modo de operaÃ§Ã£o: `bulk` (leitura completa das tabelas)
- Principais configs:
  - `connector.class`: `io.confluent.connect.jdbc.JdbcSourceConnector`
  - `connection.url`: URL de conexÃ£o JDBC para PostgreSQL
  - `table.whitelist`: `dadostesouroipca_gold`, `dadostesouropre_gold`
  - `topic.prefix`: `postgres-`
  - `mode`: `bulk`
  - `tasks.max`: `1`

### ğŸª£ S3 Sink Connector

- Grava os dados dos tÃ³picos Kafka em arquivos JSON no S3
- Principais configs:
  - `connector.class`: `io.confluent.connect.s3.S3SinkConnector`
  - `topics`: `postgres-dadostesouroipca_gold`, `postgres-dadostesouropre_gold`
  - `s3.bucket.name`: nome do bucket na AWS
  - `format.class`: `io.confluent.connect.s3.format.json.JsonFormat`
  - `flush.size`: define a frequÃªncia de gravaÃ§Ã£o
  - Credenciais AWS via variÃ¡veis de ambiente

---

## ğŸš€ Como Rodar

1. **Iniciar os conectores JDBC Source**

```bash
curl -X POST -H "Content-Type: application/json" \
  --data @connect_jdbc_postgres_ipca_gold.config \
  http://localhost:8083/connectors

curl -X POST -H "Content-Type: application/json" \
  --data @connect_jdbc_postgres_pre_gold.config \
  http://localhost:8083/connectors

curl http://localhost:8083/connectors/postg-connector-ipca-gold/status
curl http://localhost:8083/connectors/postg-connector-pre-gold/status

curl -X POST -H "Content-Type: application/json" \
  --data @connect_s3_sink_ipca_gold.config \
  http://localhost:8083/connectors

curl -X POST -H "Content-Type: application/json" \
  --data @connect_s3_sink_pre_gold.config \
  http://localhost:8083/connectors

curl http://localhost:8083/connectors/s3-sink-connector-ipca-gold/status
curl http://localhost:8083/connectors/s3-sink-connector-pre-gold/status
```

## âœ… ValidaÃ§Ã£o

Para inspecionar os dados diretamente nos tÃ³picos Kafka:

```bash
docker exec -it broker kafka-console-consumer \
  --bootstrap-server broker:9092 \
  --topic postgres-dadostesouroipca_gold \
  --from-beginning --max-messages 5

docker exec -it broker kafka-console-consumer \
  --bootstrap-server broker:9092 \
  --topic postgres-dadostesouropre_gold \
  --from-beginning --max-messages 5
```

## ğŸ“ ObservaÃ§Ãµes

O pipeline estÃ¡ desenhado para rodar continuamente, mantendo os dados sincronizados entre **PostgreSQL**, **Kafka** e **S3**.

As configuraÃ§Ãµes podem ser facilmente adaptadas para modos como `timestamp+incrementing` ou `incrementing`, caso vocÃª precise de captura de alteraÃ§Ãµes (CDC).

Todos os conectores estÃ£o em formato `.config` (JSON) e versionados no repositÃ³rio.
