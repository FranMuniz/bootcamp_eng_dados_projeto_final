# Pipeline Kafka Connect: PostgreSQL (Gold) ‚Üí Kafka ‚Üí AWS S3

Este projeto implementa uma solu√ß√£o completa de Engenharia de Dados por meio de um pipeline ETL estruturado em tr√™s camadas: **Bronze**, **Silver** e **Gold**. A orquestra√ß√£o √© realizada com o **Apache Airflow**, agendando execu√ß√µes a cada **10 minutos**, o que caracteriza um modelo de processamento do tipo **micro-batch**. Esse formato garante um bom equil√≠brio entre lat√™ncia e efici√™ncia, permitindo atualiza√ß√µes frequentes e consistentes no Data Lake.

A arquitetura do projeto integra tecnologias amplamente utilizadas no mercado, como **Apache Kafka**, **Apache Spark**, **PostgreSQL**, **Amazon S3** e **Kafka Connect**, todas operando em um ambiente totalmente **dockerizado**.

O pipeline conecta as **tabelas Gold** do PostgreSQL (`dadostesouroipca_gold` e `dadostesouropre_gold`) a **t√≥picos Kafka**, que por sua vez alimentam arquivos no formato **JSON** organizados no **AWS S3**, garantindo a **sincroniza√ß√£o cont√≠nua dos dados** para consumo em sistemas downstream.

---

### üéØ Objetivos T√©cnicos

1. **Ingest√£o de Dados com Kafka e PostgreSQL**  
   Implementa√ß√£o de pipelines de ingest√£o bruta usando Apache Kafka, com dados inicialmente armazenados em PostgreSQL. Servi√ßos configurados via Docker Compose para garantir reprodutibilidade e isolamento.

2. **Cria√ß√£o de Pipelines ETL com Spark SQL**  
   Estrutura de processamento em camadas para limpeza, transforma√ß√£o e enriquecimento dos dados:

   - ü•â **Pipeline Bronze - Ingest√£o Bruta**  
     - **Fonte:** Arquivos JSON com inconsist√™ncias e poss√≠veis duplica√ß√µes  
     - **Processamento:** Leitura via Spark e valida√ß√£o do schema  
     - **Destino:** Tabela Bronze no PostgreSQL

   - ü•à **Pipeline Silver - Limpeza e Transforma√ß√£o**  
     - **Fonte:** Tabela Bronze  
     - **Processamento:**  
       - Remo√ß√£o de duplicatas  
       - Tratamento de nulos e registros inv√°lidos  
       - Padroniza√ß√£o de formatos (strings, datas, etc.)  
     - **Destino:** Tabela Silver no PostgreSQL

   - ü•á **Pipeline Gold - Agrega√ß√£o e Enriquecimento**  
     - **Fonte:** Tabela Silver  
     - **Processamento:**  
       - C√°lculo de m√©tricas agregadas (ex.: totais, m√©dias)  
       - Prepara√ß√£o dos dados para an√°lise  
     - **Destino:** Tabela Gold no PostgreSQL

3. **Integra√ß√£o com Data Lake no S3 via Kafka Connect**  
   Configura√ß√£o de Kafka Connect Sink para envio dos dados Gold ao Data Lake na Amazon S3, com particionamento e organiza√ß√£o adequados.

4. **Orquestra√ß√£o com Apache Airflow**  
   Orquestra√ß√£o dos pipelines Bronze ‚Üí Silver ‚Üí Gold para garantir execu√ß√£o ordenada e monitorada.

---

### üì∏ Evid√™ncias do Projeto (Entreg√°veis)

- Tabelas carregadas no PostgreSQL (Bronze, Silver, Gold)  
- C√≥digos Spark SQL utilizados (prints e logs)  
- Configura√ß√µes dos t√≥picos Kafka e Connectors  
- Logs e screenshots da execu√ß√£o dos pipelines  
- Dados organizados e particionados no Amazon S3  

---

## ‚öôÔ∏è Configura√ß√£o dos Conectores

### üîå JDBC Source Connector

- Modo de opera√ß√£o: `bulk` (leitura completa das tabelas)  
- Principais configura√ß√µes:  
  - `connector.class`: `io.confluent.connect.jdbc.JdbcSourceConnector`  
  - `connection.url`: JDBC URL para PostgreSQL  
  - `table.whitelist`: `dadostesouroipca_gold`, `dadostesouropre_gold`  
  - `topic.prefix`: `postgres-`  
  - `mode`: `bulk`  
  - `tasks.max`: `1`  

### ü™£ S3 Sink Connector

- Grava dados dos t√≥picos Kafka em arquivos JSON no S3  
- Principais configura√ß√µes:  
  - `connector.class`: `io.confluent.connect.s3.S3SinkConnector`  
  - `topics`: `postgres-dadostesouroipca_gold`, `postgres-dadostesouropre_gold`  
  - `s3.bucket.name`: nome do bucket AWS  
  - `format.class`: `io.confluent.connect.s3.format.json.JsonFormat`  
  - `flush.size`: frequ√™ncia de grava√ß√£o  
  - Credenciais AWS via vari√°veis de ambiente  

---

### üöÄ Como Rodar

1. **Iniciar os conectores JDBC Source**

```bash
curl -X POST -H "Content-Type: application/json" \
  --data @connect_jdbc_postgres_ipca_gold.config \
  http://localhost:8083/connectors

curl -X POST -H "Content-Type: application/json" \
  --data @connect_jdbc_postgres_pre_gold.config \
  http://localhost:8083/connectors

curl http://localhost:8083/connectors/postg-connector-ipca-gold/status
curl http://localhost:8083/connectors/postg-connector-pre-gold/status

curl -X POST -H "Content-Type: application/json" \
  --data @connect_s3_sink_ipca_gold.config \
  http://localhost:8083/connectors

curl -X POST -H "Content-Type: application/json" \
  --data @connect_s3_sink_pre_gold.config \
  http://localhost:8083/connectors

curl http://localhost:8083/connectors/s3-sink-connector-ipca-gold/status
curl http://localhost:8083/connectors/s3-sink-connector-pre-gold/status
```

## ‚úÖ Valida√ß√£o

Para inspecionar os dados diretamente nos t√≥picos Kafka:

```bash
docker exec -it broker kafka-console-consumer \
  --bootstrap-server broker:9092 \
  --topic postgres-dadostesouroipca_gold \
  --from-beginning --max-messages 5

docker exec -it broker kafka-console-consumer \
  --bootstrap-server broker:9092 \
  --topic postgres-dadostesouropre_gold \
  --from-beginning --max-messages 5
```

---

### üë©‚Äçüíª Autor

Este projeto foi desenvolvido por **Francieli Muniz** para fins **educacionais e de aprendizado pr√°tico** em engenharia de dados.

Caso tenha d√∫vidas, sugest√µes ou queira colaborar, fique √† vontade para entrar em contato!

