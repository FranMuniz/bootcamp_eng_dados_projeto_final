# üåÄ Pipeline Kafka Connect: PostgreSQL (Gold) ‚Üí Kafka ‚Üí AWS S3

## üìò Descri√ß√£o

Este projeto desenvolve uma solu√ß√£o completa de Engenharia de Dados utilizando um pipeline ETL estruturado em tr√™s camadas (Bronze, Silver e Gold), com orquestra√ß√£o opcional via Airflow. A arquitetura integra tecnologias amplamente utilizadas no mercado, como Apache Kafka, Apache Spark, PostgreSQL, Amazon S3 e Kafka Connect, todos executados em ambiente Dockerizado.

O pipeline conecta as **tabelas Gold** do PostgreSQL (`dadostesouroipca_gold` e `dadostesouropre_gold`) a **t√≥picos Kafka**, que alimentam arquivos JSON organizados no **AWS S3**, garantindo a **sincroniza√ß√£o cont√≠nua** dos dados para consumo downstream.

---

## üéØ Objetivos T√©cnicos

1. **Ingest√£o de Dados com Kafka e PostgreSQL**  
   Implementa√ß√£o de pipelines de ingest√£o bruta usando Apache Kafka, com dados inicialmente armazenados em PostgreSQL. Servi√ßos configurados via Docker Compose para garantir reprodutibilidade e isolamento.

2. **Cria√ß√£o de Pipelines ETL com Spark SQL**  
   Processamento dos dados em camadas:  
   - **Bronze:** Ingest√£o bruta de arquivos JSON com sujeiras e duplica√ß√µes.  
   - **Silver:** Limpeza, tratamento de dados ausentes e padroniza√ß√£o.  
   - **Gold:** Gera√ß√£o de m√©tricas e dados prontos para an√°lise.

3. **Integra√ß√£o com Data Lake no S3 via Kafka Connect**  
   Configura√ß√£o de Kafka Connect Sink para envio dos dados Gold ao Data Lake na Amazon S3, com particionamento e organiza√ß√£o adequados.

4. **Orquestra√ß√£o com Apache Airflow (opcional)**  
   Orquestra√ß√£o dos pipelines Bronze ‚Üí Silver ‚Üí Gold para garantir execu√ß√£o ordenada e monitorada.

---

## üß± Estrutura dos Pipelines

### ü•â Pipeline Bronze - Ingest√£o Bruta
- **Fonte:** Arquivo JSON com inconsist√™ncias  
- **Processamento:** Leitura via Spark e valida√ß√£o do schema  
- **Destino:** Tabela Bronze no PostgreSQL ou armazenamento em Parquet/Delta

### ü•à Pipeline Silver - Limpeza e Transforma√ß√£o
- **Fonte:** Tabela Bronze  
- **Processamento:**  
  - Remo√ß√£o de duplicatas  
  - Tratamento de nulos e registros inv√°lidos  
  - Padroniza√ß√£o de formatos (strings, datas, etc.)  
- **Destino:** Tabela Silver no PostgreSQL

### ü•á Pipeline Gold - Agrega√ß√£o e Enriquecimento
- **Fonte:** Tabela Silver  
- **Processamento:**  
  - C√°lculo de m√©tricas agregadas (ex.: totais, m√©dias)  
  - Dados prontos para an√°lise  
- **Destino:** Tabela Gold no PostgreSQL

---

## üèóÔ∏è Arquitetura do Pipeline

1. **üì° Fonte de Dados:** PostgreSQL (camada Gold: IPCA e Prefixado)  
2. **üîÑ Kafka Connect - JDBC Source:** extrai dados do PostgreSQL e publica nos t√≥picos Kafka  
3. **üß© Kafka Broker:** armazena os t√≥picos atualizados  
4. **üå© Kafka Connect - S3 Sink:** consome t√≥picos e grava arquivos JSON no bucket AWS S3  

---

## üì∏ Evid√™ncias do Projeto (Entreg√°veis)

- Tabelas carregadas no PostgreSQL (Bronze, Silver, Gold)  
- C√≥digos Spark SQL utilizados (prints e logs)  
- Configura√ß√µes dos t√≥picos Kafka e Connectors  
- Logs e screenshots da execu√ß√£o dos pipelines  
- Dados organizados e particionados no Amazon S3  

---

## ‚öôÔ∏è Configura√ß√£o dos Conectores

### üîå JDBC Source Connector

- Modo de opera√ß√£o: `bulk` (leitura completa das tabelas)  
- Principais configura√ß√µes:  
  - `connector.class`: `io.confluent.connect.jdbc.JdbcSourceConnector`  
  - `connection.url`: JDBC URL para PostgreSQL  
  - `table.whitelist`: `dadostesouroipca_gold`, `dadostesouropre_gold`  
  - `topic.prefix`: `postgres-`  
  - `mode`: `bulk`  
  - `tasks.max`: `1`  

### ü™£ S3 Sink Connector

- Grava dados dos t√≥picos Kafka em arquivos JSON no S3  
- Principais configura√ß√µes:  
  - `connector.class`: `io.confluent.connect.s3.S3SinkConnector`  
  - `topics`: `postgres-dadostesouroipca_gold`, `postgres-dadostesouropre_gold`  
  - `s3.bucket.name`: nome do bucket AWS  
  - `format.class`: `io.confluent.connect.s3.format.json.JsonFormat`  
  - `flush.size`: frequ√™ncia de grava√ß√£o  
  - Credenciais AWS via vari√°veis de ambiente  

---

## üöÄ Como Rodar

1. **Iniciar os conectores JDBC Source**

```bash
curl -X POST -H "Content-Type: application/json" \
  --data @connect_jdbc_postgres_ipca_gold.config \
  http://localhost:8083/connectors

curl -X POST -H "Content-Type: application/json" \
  --data @connect_jdbc_postgres_pre_gold.config \
  http://localhost:8083/connectors

curl http://localhost:8083/connectors/postg-connector-ipca-gold/status
curl http://localhost:8083/connectors/postg-connector-pre-gold/status

curl -X POST -H "Content-Type: application/json" \
  --data @connect_s3_sink_ipca_gold.config \
  http://localhost:8083/connectors

curl -X POST -H "Content-Type: application/json" \
  --data @connect_s3_sink_pre_gold.config \
  http://localhost:8083/connectors

curl http://localhost:8083/connectors/s3-sink-connector-ipca-gold/status
curl http://localhost:8083/connectors/s3-sink-connector-pre-gold/status
```

## ‚úÖ Valida√ß√£o

Para inspecionar os dados diretamente nos t√≥picos Kafka:

```bash
docker exec -it broker kafka-console-consumer \
  --bootstrap-server broker:9092 \
  --topic postgres-dadostesouroipca_gold \
  --from-beginning --max-messages 5

docker exec -it broker kafka-console-consumer \
  --bootstrap-server broker:9092 \
  --topic postgres-dadostesouropre_gold \
  --from-beginning --max-messages 5
```

---

### üë©‚Äçüíª Autor

Este projeto foi desenvolvido por **Francieli Muniz** para fins **educacionais e de aprendizado pr√°tico** em engenharia de dados.

Caso tenha d√∫vidas, sugest√µes ou queira colaborar, fique √† vontade para entrar em contato!

